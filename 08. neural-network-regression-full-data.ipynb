{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table(\"data/airfoil_self_noise.dat\", \n",
    "                        header=None, \n",
    "                        names=['frequency', 'angle_of_attack', 'chord_length', 'free_stream_velocity', \n",
    "                               'suction_side_displacement_thickness', 'scaled_sound_pressure_level'])\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.00e+02, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.00e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.25e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       ...,\n       [4.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [5.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [6.30e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02]])"
     },
     "metadata": {},
     "execution_count": 622
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([126.2 , 125.2 , 125.95, ..., 106.6 , 106.22, 104.2 ])"
     },
     "metadata": {},
     "execution_count": 623
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "regressor = tf.keras.models.Sequential()\n",
    "regressor.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "regressor.add(tf.keras.layers.Dense(units=1))\n",
    "regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n226/226 [==============================] - 1s 2ms/step - loss: 14586.6777\nEpoch 2/50\n226/226 [==============================] - 0s 736us/step - loss: 10670.7212\nEpoch 3/50\n226/226 [==============================] - 0s 659us/step - loss: 7850.3033\nEpoch 4/50\n226/226 [==============================] - 0s 655us/step - loss: 5678.9758\nEpoch 5/50\n226/226 [==============================] - 0s 656us/step - loss: 3963.7582\nEpoch 6/50\n226/226 [==============================] - 0s 865us/step - loss: 2743.9723\nEpoch 7/50\n226/226 [==============================] - 0s 717us/step - loss: 1779.0532\nEpoch 8/50\n226/226 [==============================] - 0s 606us/step - loss: 1127.8020\nEpoch 9/50\n226/226 [==============================] - 0s 584us/step - loss: 713.0611\nEpoch 10/50\n226/226 [==============================] - 0s 575us/step - loss: 390.8153\nEpoch 11/50\n226/226 [==============================] - 0s 588us/step - loss: 230.1465\nEpoch 12/50\n226/226 [==============================] - 0s 748us/step - loss: 143.1515\nEpoch 13/50\n226/226 [==============================] - 0s 717us/step - loss: 88.9562\nEpoch 14/50\n226/226 [==============================] - 0s 655us/step - loss: 65.2705\nEpoch 15/50\n226/226 [==============================] - 0s 566us/step - loss: 53.4388\nEpoch 16/50\n226/226 [==============================] - 0s 566us/step - loss: 51.0945\nEpoch 17/50\n226/226 [==============================] - 0s 593us/step - loss: 47.0416\nEpoch 18/50\n226/226 [==============================] - 0s 566us/step - loss: 47.0547\nEpoch 19/50\n226/226 [==============================] - 0s 642us/step - loss: 47.2261\nEpoch 20/50\n226/226 [==============================] - 0s 783us/step - loss: 46.3644\nEpoch 21/50\n226/226 [==============================] - 0s 721us/step - loss: 37.6956\nEpoch 22/50\n226/226 [==============================] - 0s 575us/step - loss: 20.8843\nEpoch 23/50\n226/226 [==============================] - 0s 562us/step - loss: 17.7555\nEpoch 24/50\n226/226 [==============================] - 0s 571us/step - loss: 17.5365\nEpoch 25/50\n226/226 [==============================] - 0s 611us/step - loss: 17.5202\nEpoch 26/50\n226/226 [==============================] - 0s 571us/step - loss: 16.2826\nEpoch 27/50\n226/226 [==============================] - 0s 580us/step - loss: 14.9969\nEpoch 28/50\n226/226 [==============================] - 0s 575us/step - loss: 16.1831\nEpoch 29/50\n226/226 [==============================] - 0s 566us/step - loss: 14.8691\nEpoch 30/50\n226/226 [==============================] - 0s 588us/step - loss: 14.3158\nEpoch 31/50\n226/226 [==============================] - 0s 580us/step - loss: 16.6186\nEpoch 32/50\n226/226 [==============================] - 0s 580us/step - loss: 15.3959\nEpoch 33/50\n226/226 [==============================] - 0s 593us/step - loss: 14.1830\nEpoch 34/50\n226/226 [==============================] - 0s 602us/step - loss: 15.7461\nEpoch 35/50\n226/226 [==============================] - 0s 571us/step - loss: 14.8065\nEpoch 36/50\n226/226 [==============================] - 0s 602us/step - loss: 14.5031\nEpoch 37/50\n226/226 [==============================] - 0s 549us/step - loss: 15.6039\nEpoch 38/50\n226/226 [==============================] - 0s 580us/step - loss: 14.0547\nEpoch 39/50\n226/226 [==============================] - 0s 584us/step - loss: 14.8854\nEpoch 40/50\n226/226 [==============================] - 0s 544us/step - loss: 12.7329\nEpoch 41/50\n226/226 [==============================] - 0s 571us/step - loss: 11.5277\nEpoch 42/50\n226/226 [==============================] - 0s 593us/step - loss: 14.6642\nEpoch 43/50\n226/226 [==============================] - 0s 580us/step - loss: 13.8470\nEpoch 44/50\n226/226 [==============================] - 0s 611us/step - loss: 12.9990\nEpoch 45/50\n226/226 [==============================] - 0s 605us/step - loss: 12.3380\nEpoch 46/50\n226/226 [==============================] - 0s 612us/step - loss: 11.9637\nEpoch 47/50\n226/226 [==============================] - 0s 584us/step - loss: 12.2412\nEpoch 48/50\n226/226 [==============================] - 0s 589us/step - loss: 11.8781\nEpoch 49/50\n226/226 [==============================] - 0s 575us/step - loss: 12.4533\nEpoch 50/50\n226/226 [==============================] - 0s 629us/step - loss: 11.2420\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2488d394490>"
     },
     "metadata": {},
     "execution_count": 627
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size=5, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[133.63 130.79]\n [119.43 119.54]\n [113.62 110.32]\n [117.32 117.4 ]\n [124.67 127.62]\n [129.17 121.66]\n [118.89 118.69]\n [132.54 130.03]\n [114.57 114.73]\n [125.05 124.21]\n [127.46 125.84]\n [132.27 131.52]\n [132.87 130.7 ]\n [118.01 117.81]\n [128.98 126.66]\n [113.24 113.14]\n [129.16 126.76]\n [132.   133.38]\n [116.57 118.08]\n [119.27 116.15]\n [121.64 123.46]\n [131.02 130.09]\n [130.72 129.93]\n [123.04 120.66]\n [131.06 134.06]\n [120.93 122.09]\n [112.69 117.09]\n [129.05 138.76]\n [129.15 130.83]\n [128.86 128.24]\n [129.15 128.95]\n [121.79 122.53]\n [110.3  103.38]\n [125.55 126.41]\n [129.14 131.8 ]\n [128.74 130.96]\n [116.51 119.25]\n [110.38 109.64]\n [128.96 127.78]\n [127.76 129.01]\n [130.7  132.54]\n [124.47 125.48]\n [124.59 138.27]\n [115.81 123.13]\n [112.37 111.03]\n [133.17 135.96]\n [129.16 127.12]\n [130.16 129.67]\n [129.23 125.65]\n [128.61 129.24]\n [124.22 123.21]\n [126.74 127.  ]\n [116.71 119.91]\n [128.44 126.56]\n [121.18 121.53]\n [122.61 122.23]\n [111.57 113.3 ]\n [128.61 128.34]\n [122.13 121.73]\n [119.98 118.9 ]\n [127.93 122.43]\n [128.75 133.24]\n [129.04 127.64]\n [133.14 136.17]\n [125.95 124.36]\n [126.63 127.59]\n [128.88 128.35]\n [129.89 133.76]\n [129.13 132.13]\n [116.9  113.8 ]\n [130.24 125.72]\n [128.93 126.09]\n [129.15 121.01]\n [128.17 130.05]\n [126.   126.65]\n [123.46 123.45]\n [128.45 122.09]\n [128.28 126.51]\n [129.39 133.66]\n [129.42 130.18]\n [129.18 129.12]\n [128.28 128.41]\n [125.64 118.11]\n [124.81 122.8 ]\n [129.13 127.31]\n [117.62 118.11]\n [127.75 128.81]\n [124.53 121.77]\n [129.34 134.53]\n [128.79 127.38]\n [128.53 130.99]\n [128.86 127.12]\n [125.85 119.11]\n [112.1  110.65]\n [129.14 126.42]\n [110.39 107.28]\n [111.62 108.19]\n [134.1  136.1 ]\n [119.22 120.51]\n [129.11 122.78]\n [125.46 125.16]\n [134.16 135.94]\n [128.38 129.01]\n [129.11 131.86]\n [134.51 133.28]\n [128.41 129.58]\n [128.71 133.05]\n [130.72 130.79]\n [129.17 131.71]\n [129.36 136.68]\n [124.25 123.23]\n [125.04 125.04]\n [127.45 127.83]\n [127.74 127.46]\n [128.86 129.09]\n [121.3  120.98]\n [129.12 130.72]\n [121.24 120.7 ]\n [129.   128.63]\n [125.39 122.2 ]\n [123.06 123.3 ]\n [128.02 119.7 ]\n [128.97 127.31]\n [129.02 127.14]\n [126.67 124.46]\n [119.63 116.02]\n [129.21 131.72]\n [128.92 129.69]\n [129.16 126.84]\n [120.23 120.65]\n [129.16 131.36]\n [123.6  123.22]\n [123.46 125.63]\n [119.93 115.44]\n [129.17 128.33]\n [126.68 125.97]\n [123.09 120.58]\n [128.79 132.66]\n [120.13 123.21]\n [113.01 112.16]\n [113.16 114.08]\n [113.5  114.67]\n [128.73 127.81]\n [120.53 123.26]\n [114.66 116.66]\n [128.41 122.97]\n [115.16 116.47]\n [130.59 129.27]\n [120.37 121.12]\n [126.   130.43]\n [126.5  125.57]\n [128.75 131.6 ]\n [127.34 119.15]\n [123.76 123.24]\n [129.2  126.51]\n [122.7  122.82]\n [129.04 133.5 ]\n [131.48 126.93]\n [122.53 119.88]\n [133.95 133.96]\n [114.13 113.73]\n [128.12 125.05]\n [122.29 125.23]\n [128.1  130.24]\n [121.89 124.51]\n [128.13 128.26]\n [126.23 124.88]\n [118.13 118.62]\n [133.88 138.54]\n [112.64 112.93]\n [112.24 113.08]\n [127.68 128.17]\n [129.15 125.81]\n [125.4  124.99]\n [128.8  126.84]\n [116.15 116.86]\n [126.51 125.72]\n [128.77 123.12]\n [126.47 125.31]\n [120.9  122.17]\n [127.85 131.46]\n [122.54 121.59]\n [132.89 134.15]\n [119.58 119.19]\n [129.3  125.95]\n [129.15 129.95]\n [128.1  127.58]\n [129.01 129.58]\n [120.73 120.26]\n [129.17 126.16]\n [120.93 124.84]\n [119.68 119.14]\n [129.12 126.81]\n [125.83 125.96]\n [119.28 118.62]\n [134.19 134.93]\n [129.1  130.72]\n [113.58 113.08]\n [129.06 121.85]\n [126.67 126.34]\n [112.86 114.45]\n [129.15 130.59]\n [127.79 126.99]\n [129.18 126.41]\n [110.88 106.11]\n [124.79 130.22]\n [128.21 131.07]\n [118.94 118.13]\n [119.75 118.55]\n [129.17 130.99]\n [134.59 130.5 ]\n [132.18 131.78]\n [129.17 127.4 ]\n [129.21 125.2 ]\n [129.18 130.03]\n [129.14 130.21]\n [129.07 138.42]\n [129.19 128.82]\n [128.87 133.61]\n [116.59 117.65]\n [126.51 130.4 ]\n [129.02 132.4 ]\n [129.08 131.75]\n [115.2  116.02]\n [128.99 123.74]\n [111.8  108.65]\n [129.14 129.88]\n [127.63 126.47]\n [129.19 128.58]\n [127.39 115.81]\n [129.07 128.18]\n [128.97 126.15]\n [129.14 126.67]\n [130.58 132.3 ]\n [116.49 117.72]\n [124.23 124.09]\n [128.63 128.44]\n [126.17 127.69]\n [117.26 118.77]\n [127.82 126.27]\n [129.16 121.06]\n [127.04 128.48]\n [127.72 126.86]\n [113.65 114.78]\n [110.53 107.15]\n [120.03 120.24]\n [128.05 127.36]\n [129.17 124.16]\n [123.61 124.36]\n [127.87 128.56]\n [110.99 108.69]\n [111.25 109.89]\n [128.46 136.41]\n [129.84 133.55]\n [125.11 125.03]\n [125.97 123.7 ]\n [118.2  120.25]\n [129.15 128.71]\n [118.19 117.14]\n [110.57 104.5 ]\n [129.22 125.35]\n [122.91 119.1 ]\n [127.25 121.24]\n [132.03 128.92]\n [129.03 125.35]\n [128.95 134.32]\n [128.76 130.56]\n [129.04 132.76]\n [127.39 120.14]\n [127.92 130.75]\n [128.21 128.68]\n [126.76 125.11]\n [133.4  134.31]\n [126.2  124.84]\n [129.12 127.56]\n [125.88 125.68]\n [129.06 122.23]\n [128.96 128.29]\n [115.68 115.14]\n [118.56 120.23]\n [115.63 116.91]\n [128.35 133.42]\n [129.02 134.51]\n [125.09 119.97]\n [113.85 117.25]\n [129.17 129.99]\n [130.89 125.27]\n [110.31 104.2 ]\n [130.   125.58]\n [120.28 119.29]\n [123.24 120.54]\n [128.81 129.28]\n [121.23 121.82]\n [122.49 121.93]\n [111.02 109.62]\n [134.07 138.61]\n [126.63 127.61]\n [129.12 130.44]\n [129.41 131.01]\n [128.3  125.58]\n [112.94 112.59]\n [129.06 127.21]\n [128.89 136.28]\n [116.79 117.5 ]\n [124.53 122.34]\n [112.9  114.04]\n [128.98 135.08]\n [125.94 127.23]\n [124.02 123.69]\n [125.61 118.  ]\n [134.39 135.35]\n [125.98 126.53]\n [128.8  135.37]\n [112.71 111.96]\n [121.19 125.82]\n [118.76 119.62]\n [128.43 132.04]\n [119.73 118.36]\n [123.97 124.75]\n [116.77 112.51]\n [122.93 122.38]\n [119.93 120.5 ]\n [123.62 121.31]\n [111.43 109.25]\n [121.42 119.5 ]\n [114.72 118.21]\n [126.31 124.36]\n [114.96 115.91]\n [129.06 139.44]\n [124.95 124.49]\n [129.55 129.68]\n [129.04 134.53]\n [114.75 114.31]\n [129.2  129.45]\n [118.27 116.41]\n [129.13 118.13]\n [118.46 118.71]\n [134.35 131.84]\n [111.71 110.91]\n [129.02 129.57]\n [125.81 124.27]\n [126.97 129.03]\n [125.35 124.85]\n [115.09 115.68]\n [112.31 117.62]\n [124.07 127.13]\n [119.26 119.38]\n [124.49 119.07]\n [122.14 118.94]\n [113.4  113.33]\n [129.14 127.7 ]\n [131.47 131.46]\n [122.62 121.48]\n [129.2  129.8 ]\n [124.45 127.04]\n [129.14 134.  ]\n [129.18 128.77]\n [126.46 124.45]\n [123.72 124.84]\n [114.69 114.9 ]\n [118.47 118.76]\n [127.76 128.35]\n [130.03 130.2 ]\n [119.06 118.14]\n [129.13 133.1 ]\n [129.04 125.73]\n [116.97 116.24]\n [124.48 124.17]\n [120.45 115.86]\n [131.22 129.97]\n [122.98 121.4 ]\n [129.17 120.77]\n [118.15 118.12]\n [129.16 132.51]\n [129.22 132.3 ]\n [129.25 127.64]]\n"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7850064094459825"
     },
     "metadata": {},
     "execution_count": 630
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10.198038520002273"
     },
     "metadata": {},
     "execution_count": 631
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.5844607849121033"
     },
     "metadata": {},
     "execution_count": 632
    }
   ],
   "source": [
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}