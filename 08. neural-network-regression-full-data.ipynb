{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table(\"data/airfoil_self_noise.dat\", \n",
    "                        header=None, \n",
    "                        names=['frequency', 'angle_of_attack', 'chord_length', 'free_stream_velocity', \n",
    "                               'suction_side_displacement_thickness', 'scaled_sound_pressure_level'])\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.00e+02, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.00e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.25e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       ...,\n       [4.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [5.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [6.30e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02]])"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([126.2 , 125.2 , 125.95, ..., 106.6 , 106.22, 104.2 ])"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "regressor = tf.keras.models.Sequential()\n",
    "regressor.add(tf.keras.layers.Dense(units=X_train.shape[0], kernel_initializer = 'uniform', activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "# regressor.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=1))\n",
    "regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience = 20),#patience=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.0823\nEpoch 120/500\n226/226 [==============================] - 0s 646us/step - loss: 64.0702\nEpoch 121/500\n226/226 [==============================] - 0s 646us/step - loss: 61.5099\nEpoch 122/500\n226/226 [==============================] - 0s 757us/step - loss: 57.6002\nEpoch 123/500\n226/226 [==============================] - 0s 677us/step - loss: 53.2307\nEpoch 124/500\n226/226 [==============================] - 0s 624us/step - loss: 55.6163\nEpoch 125/500\n226/226 [==============================] - 0s 655us/step - loss: 50.0681\nEpoch 126/500\n226/226 [==============================] - 0s 690us/step - loss: 46.8897\nEpoch 127/500\n226/226 [==============================] - 0s 655us/step - loss: 50.3145\nEpoch 128/500\n226/226 [==============================] - 0s 721us/step - loss: 48.1680\nEpoch 129/500\n226/226 [==============================] - 0s 695us/step - loss: 40.0818\nEpoch 130/500\n226/226 [==============================] - 0s 668us/step - loss: 27.2824\nEpoch 131/500\n226/226 [==============================] - 0s 664us/step - loss: 24.7744\nEpoch 132/500\n226/226 [==============================] - 0s 659us/step - loss: 21.3347\nEpoch 133/500\n226/226 [==============================] - 0s 651us/step - loss: 20.5366\nEpoch 134/500\n226/226 [==============================] - 0s 765us/step - loss: 16.5289\nEpoch 135/500\n226/226 [==============================] - 0s 832us/step - loss: 16.4103\nEpoch 136/500\n226/226 [==============================] - 0s 867us/step - loss: 15.3145\nEpoch 137/500\n226/226 [==============================] - 0s 872us/step - loss: 15.8172\nEpoch 138/500\n226/226 [==============================] - 0s 969us/step - loss: 16.6778\nEpoch 139/500\n226/226 [==============================] - 0s 876us/step - loss: 13.0016\nEpoch 140/500\n226/226 [==============================] - 0s 903us/step - loss: 13.8606\nEpoch 141/500\n226/226 [==============================] - 0s 911us/step - loss: 14.0784\nEpoch 142/500\n226/226 [==============================] - 0s 978us/step - loss: 15.0300\nEpoch 143/500\n226/226 [==============================] - 0s 942us/step - loss: 14.5752\nEpoch 144/500\n226/226 [==============================] - 0s 960us/step - loss: 14.2013\nEpoch 145/500\n226/226 [==============================] - 0s 979us/step - loss: 13.8574\nEpoch 146/500\n226/226 [==============================] - 0s 965us/step - loss: 13.3149\nEpoch 147/500\n226/226 [==============================] - 0s 1ms/step - loss: 12.3592\nEpoch 148/500\n226/226 [==============================] - 0s 841us/step - loss: 13.7111\nEpoch 149/500\n226/226 [==============================] - 0s 867us/step - loss: 13.9139\nEpoch 150/500\n226/226 [==============================] - 0s 925us/step - loss: 12.3444\nEpoch 151/500\n226/226 [==============================] - 0s 956us/step - loss: 12.1624\nEpoch 152/500\n226/226 [==============================] - 0s 894us/step - loss: 14.3963\nEpoch 153/500\n226/226 [==============================] - 0s 867us/step - loss: 12.9929\nEpoch 154/500\n226/226 [==============================] - 0s 951us/step - loss: 13.1278\nEpoch 155/500\n226/226 [==============================] - 0s 890us/step - loss: 13.2019\nEpoch 156/500\n226/226 [==============================] - 0s 880us/step - loss: 13.6844\nEpoch 157/500\n226/226 [==============================] - 0s 881us/step - loss: 12.3894\nEpoch 158/500\n226/226 [==============================] - 0s 925us/step - loss: 13.2616\nEpoch 159/500\n226/226 [==============================] - 0s 942us/step - loss: 12.3998\nEpoch 160/500\n226/226 [==============================] - 0s 982us/step - loss: 12.6330\nEpoch 161/500\n226/226 [==============================] - 0s 912us/step - loss: 12.4315\nEpoch 162/500\n226/226 [==============================] - 0s 845us/step - loss: 12.4636\nEpoch 163/500\n226/226 [==============================] - 0s 832us/step - loss: 15.6739\nEpoch 164/500\n226/226 [==============================] - 0s 929us/step - loss: 12.8407\nEpoch 165/500\n226/226 [==============================] - 0s 987us/step - loss: 14.1148\nEpoch 166/500\n226/226 [==============================] - 0s 898us/step - loss: 12.8834\nEpoch 167/500\n226/226 [==============================] - 0s 907us/step - loss: 12.2432\nEpoch 168/500\n226/226 [==============================] - 0s 920us/step - loss: 12.6517\nEpoch 169/500\n226/226 [==============================] - 0s 876us/step - loss: 13.4109\nEpoch 170/500\n226/226 [==============================] - 0s 1ms/step - loss: 13.6329\nEpoch 171/500\n226/226 [==============================] - 0s 881us/step - loss: 13.9515\nEpoch 172/500\n226/226 [==============================] - 0s 863us/step - loss: 12.4924\nEpoch 173/500\n226/226 [==============================] - 0s 1ms/step - loss: 12.7213\nEpoch 174/500\n226/226 [==============================] - 0s 1ms/step - loss: 14.4234\nEpoch 175/500\n226/226 [==============================] - 0s 894us/step - loss: 13.0646\nEpoch 176/500\n226/226 [==============================] - 0s 881us/step - loss: 12.3221\nEpoch 177/500\n226/226 [==============================] - 0s 991us/step - loss: 12.0710\nEpoch 178/500\n226/226 [==============================] - 0s 876us/step - loss: 12.2861\nEpoch 179/500\n226/226 [==============================] - 0s 987us/step - loss: 11.7035\nEpoch 180/500\n226/226 [==============================] - 0s 872us/step - loss: 10.7065\nEpoch 181/500\n226/226 [==============================] - 0s 876us/step - loss: 9.7936\nEpoch 182/500\n226/226 [==============================] - 0s 885us/step - loss: 8.7686\nEpoch 183/500\n226/226 [==============================] - 0s 867us/step - loss: 6.2081\nEpoch 184/500\n226/226 [==============================] - 0s 889us/step - loss: 5.9904\nEpoch 185/500\n226/226 [==============================] - 0s 854us/step - loss: 5.1759\nEpoch 186/500\n226/226 [==============================] - 0s 965us/step - loss: 6.4222\nEpoch 187/500\n226/226 [==============================] - 0s 1ms/step - loss: 5.3781\nEpoch 188/500\n226/226 [==============================] - 0s 951us/step - loss: 5.1357\nEpoch 189/500\n226/226 [==============================] - 0s 903us/step - loss: 4.8342\nEpoch 190/500\n226/226 [==============================] - 0s 965us/step - loss: 4.7305\nEpoch 191/500\n226/226 [==============================] - 0s 854us/step - loss: 4.0871\nEpoch 192/500\n226/226 [==============================] - 0s 876us/step - loss: 4.7243\nEpoch 193/500\n226/226 [==============================] - 0s 1ms/step - loss: 5.0477\nEpoch 194/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.9264\nEpoch 195/500\n226/226 [==============================] - 0s 1ms/step - loss: 4.3870\nEpoch 196/500\n226/226 [==============================] - 0s 1ms/step - loss: 4.4535\nEpoch 197/500\n226/226 [==============================] - 0s 1ms/step - loss: 5.2797\nEpoch 198/500\n226/226 [==============================] - 0s 845us/step - loss: 3.4750\nEpoch 199/500\n226/226 [==============================] - 0s 920us/step - loss: 4.5405\nEpoch 200/500\n226/226 [==============================] - 0s 1ms/step - loss: 4.5427\nEpoch 201/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.7946\nEpoch 202/500\n226/226 [==============================] - 0s 982us/step - loss: 3.6085\nEpoch 203/500\n226/226 [==============================] - 0s 881us/step - loss: 4.4586\nEpoch 204/500\n226/226 [==============================] - 0s 898us/step - loss: 4.1655\nEpoch 205/500\n226/226 [==============================] - 0s 872us/step - loss: 3.5152\nEpoch 206/500\n226/226 [==============================] - 0s 885us/step - loss: 3.6414\nEpoch 207/500\n226/226 [==============================] - 0s 863us/step - loss: 3.3684\nEpoch 208/500\n226/226 [==============================] - 0s 898us/step - loss: 4.2916\nEpoch 209/500\n226/226 [==============================] - 0s 889us/step - loss: 3.2660\nEpoch 210/500\n226/226 [==============================] - 0s 903us/step - loss: 4.1828\nEpoch 211/500\n226/226 [==============================] - 0s 898us/step - loss: 3.6574\nEpoch 212/500\n226/226 [==============================] - 0s 889us/step - loss: 3.7984\nEpoch 213/500\n226/226 [==============================] - 0s 845us/step - loss: 3.1059\nEpoch 214/500\n226/226 [==============================] - 0s 898us/step - loss: 3.0533\nEpoch 215/500\n226/226 [==============================] - 0s 907us/step - loss: 3.9668\nEpoch 216/500\n226/226 [==============================] - 0s 942us/step - loss: 3.9654\nEpoch 217/500\n226/226 [==============================] - 0s 991us/step - loss: 3.0514\nEpoch 218/500\n226/226 [==============================] - 0s 964us/step - loss: 3.5033\nEpoch 219/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.0546\nEpoch 220/500\n226/226 [==============================] - 0s 996us/step - loss: 3.7002\nEpoch 221/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.9622\nEpoch 222/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.6991\nEpoch 223/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.0385\nEpoch 224/500\n226/226 [==============================] - 0s 2ms/step - loss: 3.5195\nEpoch 225/500\n226/226 [==============================] - 0s 2ms/step - loss: 3.3302\nEpoch 226/500\n226/226 [==============================] - 0s 2ms/step - loss: 3.1934\nEpoch 227/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.2601\nEpoch 228/500\n226/226 [==============================] - 0s 1ms/step - loss: 3.0384\nEpoch 229/500\n226/226 [==============================] - 0s 987us/step - loss: 2.8651\nEpoch 230/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.7321\nEpoch 231/500\n226/226 [==============================] - 0s 920us/step - loss: 2.9009\nEpoch 232/500\n226/226 [==============================] - 0s 850us/step - loss: 2.3260\nEpoch 233/500\n226/226 [==============================] - 0s 881us/step - loss: 2.9457\nEpoch 234/500\n226/226 [==============================] - 0s 823us/step - loss: 2.7370\nEpoch 235/500\n226/226 [==============================] - 0s 863us/step - loss: 2.6718\nEpoch 236/500\n226/226 [==============================] - 0s 858us/step - loss: 3.3026\nEpoch 237/500\n226/226 [==============================] - 0s 894us/step - loss: 2.8066\nEpoch 238/500\n226/226 [==============================] - 0s 841us/step - loss: 2.3906\nEpoch 239/500\n226/226 [==============================] - 0s 885us/step - loss: 2.3648\nEpoch 240/500\n226/226 [==============================] - 0s 885us/step - loss: 2.3234\nEpoch 241/500\n226/226 [==============================] - 0s 894us/step - loss: 2.5560\nEpoch 242/500\n226/226 [==============================] - 0s 894us/step - loss: 3.1686\nEpoch 243/500\n226/226 [==============================] - 0s 872us/step - loss: 2.4419\nEpoch 244/500\n226/226 [==============================] - 0s 863us/step - loss: 2.7243\nEpoch 245/500\n226/226 [==============================] - 0s 876us/step - loss: 2.5665\nEpoch 246/500\n226/226 [==============================] - 0s 872us/step - loss: 2.5476\nEpoch 247/500\n226/226 [==============================] - 0s 876us/step - loss: 2.4112\nEpoch 248/500\n226/226 [==============================] - 0s 885us/step - loss: 2.5322\nEpoch 249/500\n226/226 [==============================] - 0s 872us/step - loss: 2.0681\nEpoch 250/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.6723\nEpoch 251/500\n226/226 [==============================] - 0s 912us/step - loss: 2.6775\nEpoch 252/500\n226/226 [==============================] - 0s 907us/step - loss: 2.3182\nEpoch 253/500\n226/226 [==============================] - 0s 867us/step - loss: 2.3327\nEpoch 254/500\n226/226 [==============================] - 0s 885us/step - loss: 1.8160\nEpoch 255/500\n226/226 [==============================] - 0s 885us/step - loss: 2.2174\nEpoch 256/500\n226/226 [==============================] - 0s 850us/step - loss: 2.5278\nEpoch 257/500\n226/226 [==============================] - 0s 881us/step - loss: 2.1674\nEpoch 258/500\n226/226 [==============================] - 0s 876us/step - loss: 2.0080\nEpoch 259/500\n226/226 [==============================] - 0s 894us/step - loss: 2.1481\nEpoch 260/500\n226/226 [==============================] - 0s 925us/step - loss: 1.7941\nEpoch 261/500\n226/226 [==============================] - 0s 898us/step - loss: 2.8657\nEpoch 262/500\n226/226 [==============================] - 0s 850us/step - loss: 1.7733\nEpoch 263/500\n226/226 [==============================] - 0s 890us/step - loss: 1.9151\nEpoch 264/500\n226/226 [==============================] - 0s 880us/step - loss: 2.1240\nEpoch 265/500\n226/226 [==============================] - 0s 880us/step - loss: 1.8066\nEpoch 266/500\n226/226 [==============================] - 0s 845us/step - loss: 2.0970\nEpoch 267/500\n226/226 [==============================] - 0s 973us/step - loss: 2.3398\nEpoch 268/500\n226/226 [==============================] - 0s 1ms/step - loss: 1.9322\nEpoch 269/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.1382\nEpoch 270/500\n226/226 [==============================] - 0s 1ms/step - loss: 1.8458\nEpoch 271/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.4469\nEpoch 272/500\n226/226 [==============================] - 0s 1ms/step - loss: 2.0394\nEpoch 273/500\n226/226 [==============================] - 0s 978us/step - loss: 2.2673\nEpoch 274/500\n226/226 [==============================] - 0s 898us/step - loss: 2.1570\nEpoch 275/500\n226/226 [==============================] - 0s 947us/step - loss: 1.8514\nEpoch 276/500\n226/226 [==============================] - 0s 894us/step - loss: 1.8493\nEpoch 277/500\n226/226 [==============================] - 0s 867us/step - loss: 1.5887\nEpoch 278/500\n226/226 [==============================] - 0s 863us/step - loss: 2.3991\nEpoch 279/500\n226/226 [==============================] - 0s 872us/step - loss: 1.6893\nEpoch 280/500\n226/226 [==============================] - 0s 881us/step - loss: 1.8854\nEpoch 281/500\n226/226 [==============================] - 0s 832us/step - loss: 1.7779\nEpoch 282/500\n226/226 [==============================] - 0s 1ms/step - loss: 1.7812\nEpoch 283/500\n226/226 [==============================] - 0s 876us/step - loss: 1.8602\nEpoch 284/500\n226/226 [==============================] - 0s 889us/step - loss: 1.6829\nEpoch 285/500\n226/226 [==============================] - 0s 880us/step - loss: 1.4305\nEpoch 286/500\n226/226 [==============================] - 0s 872us/step - loss: 2.7111\nEpoch 287/500\n226/226 [==============================] - 0s 867us/step - loss: 1.8158\nEpoch 288/500\n226/226 [==============================] - 0s 867us/step - loss: 2.6150\nEpoch 289/500\n226/226 [==============================] - 0s 823us/step - loss: 2.0084\nEpoch 290/500\n226/226 [==============================] - 0s 850us/step - loss: 1.7008\nEpoch 291/500\n226/226 [==============================] - 0s 991us/step - loss: 1.7708\nEpoch 292/500\n226/226 [==============================] - 0s 845us/step - loss: 1.7292\nEpoch 293/500\n226/226 [==============================] - 0s 850us/step - loss: 1.8784\nEpoch 294/500\n226/226 [==============================] - 0s 850us/step - loss: 2.1876\nEpoch 295/500\n226/226 [==============================] - 0s 907us/step - loss: 1.8598\nEpoch 296/500\n226/226 [==============================] - 0s 925us/step - loss: 1.8011\nEpoch 297/500\n226/226 [==============================] - 0s 867us/step - loss: 2.2788\nEpoch 298/500\n226/226 [==============================] - 0s 872us/step - loss: 1.3970\nEpoch 299/500\n226/226 [==============================] - 0s 925us/step - loss: 2.2149\nEpoch 300/500\n226/226 [==============================] - 0s 850us/step - loss: 1.5838\nEpoch 301/500\n226/226 [==============================] - 0s 832us/step - loss: 1.8705\nEpoch 302/500\n226/226 [==============================] - 0s 863us/step - loss: 1.6654\nEpoch 303/500\n226/226 [==============================] - 0s 894us/step - loss: 1.9336\nEpoch 304/500\n226/226 [==============================] - 0s 867us/step - loss: 2.1111\nEpoch 305/500\n226/226 [==============================] - 0s 850us/step - loss: 1.7901\nEpoch 306/500\n226/226 [==============================] - 0s 854us/step - loss: 1.3229\nEpoch 307/500\n226/226 [==============================] - 0s 872us/step - loss: 1.6097\nEpoch 308/500\n226/226 [==============================] - 0s 898us/step - loss: 1.4906\nEpoch 309/500\n226/226 [==============================] - 0s 845us/step - loss: 1.7793\nEpoch 310/500\n226/226 [==============================] - 0s 836us/step - loss: 1.3175\nEpoch 311/500\n226/226 [==============================] - 0s 956us/step - loss: 1.4962\nEpoch 312/500\n226/226 [==============================] - 0s 881us/step - loss: 1.7588\nEpoch 313/500\n226/226 [==============================] - 0s 863us/step - loss: 1.7659\nEpoch 314/500\n226/226 [==============================] - 0s 867us/step - loss: 1.5372\nEpoch 315/500\n226/226 [==============================] - 0s 889us/step - loss: 1.7555\nEpoch 316/500\n226/226 [==============================] - 0s 863us/step - loss: 1.6861\nEpoch 317/500\n226/226 [==============================] - 0s 854us/step - loss: 1.4180\nEpoch 318/500\n226/226 [==============================] - 0s 876us/step - loss: 1.6206\nEpoch 319/500\n226/226 [==============================] - 0s 894us/step - loss: 1.7873\nEpoch 320/500\n226/226 [==============================] - 0s 858us/step - loss: 1.6498\nEpoch 321/500\n226/226 [==============================] - 0s 858us/step - loss: 1.4566\nEpoch 322/500\n226/226 [==============================] - 0s 823us/step - loss: 1.5508\nEpoch 323/500\n226/226 [==============================] - 0s 841us/step - loss: 1.7523\nEpoch 324/500\n226/226 [==============================] - 0s 872us/step - loss: 2.0993\nEpoch 325/500\n226/226 [==============================] - 0s 850us/step - loss: 1.7304\nEpoch 326/500\n226/226 [==============================] - 0s 814us/step - loss: 1.4126\nEpoch 327/500\n226/226 [==============================] - 0s 832us/step - loss: 1.3530\nEpoch 328/500\n226/226 [==============================] - 0s 845us/step - loss: 1.7915\nEpoch 329/500\n226/226 [==============================] - 0s 858us/step - loss: 1.5757\nEpoch 330/500\n226/226 [==============================] - 0s 889us/step - loss: 1.0328\nEpoch 331/500\n226/226 [==============================] - 0s 1ms/step - loss: 1.5009\nEpoch 332/500\n226/226 [==============================] - 0s 876us/step - loss: 2.0879\nEpoch 333/500\n226/226 [==============================] - 0s 876us/step - loss: 1.3790\nEpoch 334/500\n226/226 [==============================] - 0s 845us/step - loss: 1.5384\nEpoch 335/500\n226/226 [==============================] - 0s 854us/step - loss: 1.8876\nEpoch 336/500\n226/226 [==============================] - 0s 867us/step - loss: 1.4305\nEpoch 337/500\n226/226 [==============================] - 0s 965us/step - loss: 1.2112\nEpoch 338/500\n226/226 [==============================] - 0s 832us/step - loss: 1.7914\nEpoch 339/500\n226/226 [==============================] - 0s 841us/step - loss: 1.5000\nEpoch 340/500\n177/226 [======================>.......] - ETA: 0s - loss: 1.765226/226 [==============================] - 0s 872us/step - loss: 1.7472\nEpoch 341/500\n226/226 [==============================] - 0s 845us/step - loss: 3.3517\nEpoch 342/500\n226/226 [==============================] - 0s 854us/step - loss: 1.0825\nEpoch 343/500\n226/226 [==============================] - 0s 841us/step - loss: 1.4873\nEpoch 344/500\n175/226 [======================>.......] - ETA: 0s - loss: 1.276226/226 [==============================] - 0s 863us/step - loss: 1.3672\nEpoch 345/500\n226/226 [==============================] - 0s 867us/step - loss: 1.5609\nEpoch 346/500\n226/226 [==============================] - 0s 845us/step - loss: 1.4993\nEpoch 347/500\n226/226 [==============================] - 0s 872us/step - loss: 1.3524\nEpoch 348/500\n226/226 [==============================] - 0s 916us/step - loss: 1.4833\nEpoch 349/500\n226/226 [==============================] - 0s 911us/step - loss: 1.1610\nEpoch 350/500\n226/226 [==============================] - 0s 1ms/step - loss: 1.4494\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1f4702120d0>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size=5, epochs=500, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[133.23 130.79]\n [119.34 119.54]\n [110.22 110.32]\n [115.55 117.4 ]\n [127.98 127.62]\n [121.45 121.66]\n [119.21 118.69]\n [127.75 130.03]\n [113.51 114.73]\n [124.1  124.21]\n [126.29 125.84]\n [132.06 131.52]\n [129.94 130.7 ]\n [117.92 117.81]\n [127.95 126.66]\n [114.47 113.14]\n [127.95 126.76]\n [133.76 133.38]\n [118.35 118.08]\n [115.05 116.15]\n [123.21 123.46]\n [129.14 130.09]\n [129.49 129.93]\n [121.72 120.66]\n [132.7  134.06]\n [121.91 122.09]\n [115.89 117.09]\n [135.55 138.76]\n [131.91 130.83]\n [128.58 128.24]\n [125.68 128.95]\n [122.96 122.53]\n [102.88 103.38]\n [124.79 126.41]\n [133.03 131.8 ]\n [130.44 130.96]\n [119.5  119.25]\n [110.48 109.64]\n [126.69 127.78]\n [126.62 129.01]\n [132.64 132.54]\n [124.53 125.48]\n [133.44 138.27]\n [124.17 123.13]\n [111.36 111.03]\n [135.29 135.96]\n [127.53 127.12]\n [129.59 129.67]\n [123.74 125.65]\n [128.47 129.24]\n [120.44 123.21]\n [126.57 127.  ]\n [117.46 119.91]\n [125.67 126.56]\n [121.46 121.53]\n [122.   122.23]\n [112.72 113.3 ]\n [127.06 128.34]\n [122.32 121.73]\n [119.07 118.9 ]\n [124.26 122.43]\n [131.84 133.24]\n [126.44 127.64]\n [134.82 136.17]\n [124.34 124.36]\n [128.94 127.59]\n [128.55 128.35]\n [131.75 133.76]\n [133.33 132.13]\n [113.34 113.8 ]\n [124.52 125.72]\n [126.97 126.09]\n [123.27 121.01]\n [129.71 130.05]\n [126.16 126.65]\n [123.65 123.45]\n [120.27 122.09]\n [124.38 126.51]\n [133.6  133.66]\n [129.92 130.18]\n [128.8  129.12]\n [127.87 128.41]\n [117.12 118.11]\n [123.35 122.8 ]\n [127.38 127.31]\n [117.66 118.11]\n [126.81 128.81]\n [123.48 121.77]\n [134.2  134.53]\n [126.46 127.38]\n [132.12 130.99]\n [127.93 127.12]\n [120.2  119.11]\n [110.24 110.65]\n [126.9  126.42]\n [106.9  107.28]\n [110.02 108.19]\n [135.49 136.1 ]\n [121.13 120.51]\n [123.   122.78]\n [125.49 125.16]\n [135.09 135.94]\n [127.68 129.01]\n [131.29 131.86]\n [133.81 133.28]\n [129.13 129.58]\n [133.92 133.05]\n [129.41 130.79]\n [131.27 131.71]\n [136.04 136.68]\n [128.17 123.23]\n [124.45 125.04]\n [127.71 127.83]\n [127.4  127.46]\n [127.97 129.09]\n [120.49 120.98]\n [131.1  130.72]\n [118.57 120.7 ]\n [128.57 128.63]\n [123.56 122.2 ]\n [123.87 123.3 ]\n [120.52 119.7 ]\n [126.88 127.31]\n [127.09 127.14]\n [126.88 124.46]\n [121.67 116.02]\n [130.95 131.72]\n [128.06 129.69]\n [127.29 126.84]\n [121.02 120.65]\n [128.8  131.36]\n [126.59 123.22]\n [124.93 125.63]\n [117.31 115.44]\n [129.46 128.33]\n [125.58 125.97]\n [120.78 120.58]\n [132.86 132.66]\n [123.21 123.21]\n [113.2  112.16]\n [113.67 114.08]\n [114.21 114.67]\n [129.64 127.81]\n [117.27 123.26]\n [116.85 116.66]\n [121.9  122.97]\n [115.78 116.47]\n [127.5  129.27]\n [120.47 121.12]\n [130.27 130.43]\n [126.71 125.57]\n [130.66 131.6 ]\n [116.11 119.15]\n [122.94 123.24]\n [121.69 126.51]\n [122.01 122.82]\n [132.93 133.5 ]\n [128.18 126.93]\n [120.46 119.88]\n [132.77 133.96]\n [114.63 113.73]\n [124.04 125.05]\n [124.66 125.23]\n [131.   130.24]\n [126.86 124.51]\n [128.21 128.26]\n [124.66 124.88]\n [118.07 118.62]\n [136.27 138.54]\n [113.7  112.93]\n [113.47 113.08]\n [128.48 128.17]\n [126.81 125.81]\n [126.58 124.99]\n [126.86 126.84]\n [115.29 116.86]\n [124.5  125.72]\n [124.65 123.12]\n [124.93 125.31]\n [120.48 122.17]\n [131.29 131.46]\n [120.52 121.59]\n [133.07 134.15]\n [119.11 119.19]\n [126.94 125.95]\n [131.33 129.95]\n [128.39 127.58]\n [130.42 129.58]\n [120.41 120.26]\n [125.95 126.16]\n [125.3  124.84]\n [117.91 119.14]\n [125.08 126.81]\n [126.49 125.96]\n [119.87 118.62]\n [134.74 134.93]\n [130.03 130.72]\n [115.32 113.08]\n [123.81 121.85]\n [124.99 126.34]\n [114.31 114.45]\n [131.7  130.59]\n [126.77 126.99]\n [125.07 126.41]\n [105.16 106.11]\n [131.7  130.22]\n [130.7  131.07]\n [118.57 118.13]\n [119.37 118.55]\n [130.34 130.99]\n [133.11 130.5 ]\n [131.25 131.78]\n [125.19 127.4 ]\n [126.72 125.2 ]\n [128.99 130.03]\n [129.65 130.21]\n [136.76 138.42]\n [127.92 128.82]\n [133.59 133.61]\n [117.08 117.65]\n [130.13 130.4 ]\n [130.92 132.4 ]\n [131.52 131.75]\n [114.76 116.02]\n [122.28 123.74]\n [111.01 108.65]\n [131.37 129.88]\n [125.85 126.47]\n [127.81 128.58]\n [118.37 115.81]\n [129.18 128.18]\n [126.51 126.15]\n [126.04 126.67]\n [132.63 132.3 ]\n [117.34 117.72]\n [124.1  124.09]\n [127.14 128.44]\n [124.92 127.69]\n [116.54 118.77]\n [125.08 126.27]\n [120.4  121.06]\n [127.55 128.48]\n [126.93 126.86]\n [113.18 114.78]\n [107.79 107.15]\n [116.75 120.24]\n [127.85 127.36]\n [124.31 124.16]\n [124.08 124.36]\n [126.8  128.56]\n [109.01 108.69]\n [109.31 109.89]\n [132.54 136.41]\n [133.25 133.55]\n [124.42 125.03]\n [122.02 123.7 ]\n [120.63 120.25]\n [127.96 128.71]\n [116.87 117.14]\n [104.71 104.5 ]\n [122.7  125.35]\n [122.11 119.1 ]\n [121.76 121.24]\n [127.41 128.92]\n [123.87 125.35]\n [135.31 134.32]\n [130.6  130.56]\n [132.24 132.76]\n [117.34 120.14]\n [129.44 130.75]\n [130.69 128.68]\n [125.37 125.11]\n [133.94 134.31]\n [125.06 124.84]\n [128.63 127.56]\n [127.78 125.68]\n [122.58 122.23]\n [127.81 128.29]\n [114.64 115.14]\n [119.41 120.23]\n [115.66 116.91]\n [131.74 133.42]\n [133.15 134.51]\n [119.09 119.97]\n [114.8  117.25]\n [129.08 129.99]\n [126.   125.27]\n [104.69 104.2 ]\n [123.76 125.58]\n [119.28 119.29]\n [120.06 120.54]\n [130.05 129.28]\n [121.63 121.82]\n [122.33 121.93]\n [106.65 109.62]\n [136.4  138.61]\n [127.91 127.61]\n [130.   130.44]\n [130.41 131.01]\n [129.05 125.58]\n [113.76 112.59]\n [126.29 127.21]\n [135.17 136.28]\n [118.24 117.5 ]\n [122.37 122.34]\n [113.28 114.04]\n [133.89 135.08]\n [126.69 127.23]\n [122.74 123.69]\n [118.92 118.  ]\n [135.49 135.35]\n [125.6  126.53]\n [133.33 135.37]\n [112.46 111.96]\n [127.23 125.82]\n [115.63 119.62]\n [132.11 132.04]\n [117.   118.36]\n [124.96 124.75]\n [112.76 112.51]\n [121.36 122.38]\n [119.2  120.5 ]\n [122.79 121.31]\n [108.17 109.25]\n [119.12 119.5 ]\n [115.71 118.21]\n [125.36 124.36]\n [114.84 115.91]\n [136.53 139.44]\n [123.79 124.49]\n [130.45 129.68]\n [133.78 134.53]\n [114.97 114.31]\n [128.7  129.45]\n [118.4  116.41]\n [119.65 118.13]\n [118.33 118.71]\n [130.95 131.84]\n [110.44 110.91]\n [130.32 129.57]\n [124.25 124.27]\n [127.82 129.03]\n [123.4  124.85]\n [115.93 115.68]\n [115.61 117.62]\n [126.41 127.13]\n [119.64 119.38]\n [120.15 119.07]\n [121.03 118.94]\n [112.81 113.33]\n [129.29 127.7 ]\n [129.77 131.46]\n [121.6  121.48]\n [128.99 129.8 ]\n [126.38 127.04]\n [133.03 134.  ]\n [129.45 128.77]\n [125.63 124.45]\n [124.19 124.84]\n [114.89 114.9 ]\n [118.84 118.76]\n [129.88 128.35]\n [128.6  130.2 ]\n [117.86 118.14]\n [132.99 133.1 ]\n [123.18 125.73]\n [116.51 116.24]\n [123.63 124.17]\n [113.26 115.86]\n [128.76 129.97]\n [121.52 121.4 ]\n [118.6  120.77]\n [117.93 118.12]\n [134.   132.51]\n [132.3  132.3 ]\n [124.47 127.64]]\n"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9593702632290961"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.9272370845079945"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.771606506347652"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "median_absolute_error(y_test, y_pred)"
   ]
  }
 ]
}