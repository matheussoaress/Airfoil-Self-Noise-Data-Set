{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table(\"data/airfoil_self_noise.dat\", \n",
    "                        header=None, \n",
    "                        names=['frequency', 'angle_of_attack', 'chord_length', 'free_stream_velocity', \n",
    "                               'suction_side_displacement_thickness', 'scaled_sound_pressure_level'])\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.00e+02, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.00e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.25e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       ...,\n       [4.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [5.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [6.30e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02]])"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([126.2 , 125.2 , 125.95, ..., 106.6 , 106.22, 104.2 ])"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "regressor = tf.keras.models.Sequential()\n",
    "regressor.add(tf.keras.layers.Dense(units=X_train.shape[0], kernel_initializer = 'uniform', activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "# regressor.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=1))\n",
    "regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience = 20),#patience=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/200\n226/226 [==============================] - 0s 694us/step - loss: 14858.0703\nEpoch 2/200\n226/226 [==============================] - 0s 779us/step - loss: 14579.4238\nEpoch 3/200\n226/226 [==============================] - 0s 673us/step - loss: 14307.7256\nEpoch 4/200\n226/226 [==============================] - 0s 704us/step - loss: 14040.9482\nEpoch 5/200\n226/226 [==============================] - 0s 704us/step - loss: 13778.2246\nEpoch 6/200\n226/226 [==============================] - 0s 686us/step - loss: 13519.2637\nEpoch 7/200\n226/226 [==============================] - 0s 805us/step - loss: 13263.7734\nEpoch 8/200\n226/226 [==============================] - 0s 730us/step - loss: 13011.5088\nEpoch 9/200\n226/226 [==============================] - 0s 664us/step - loss: 12762.4365\nEpoch 10/200\n226/226 [==============================] - 0s 668us/step - loss: 12516.3154\nEpoch 11/200\n226/226 [==============================] - 0s 686us/step - loss: 12273.1895\nEpoch 12/200\n226/226 [==============================] - 0s 695us/step - loss: 12032.9316\nEpoch 13/200\n226/226 [==============================] - 0s 673us/step - loss: 11795.4805\nEpoch 14/200\n226/226 [==============================] - 0s 650us/step - loss: 11560.8252\nEpoch 15/200\n226/226 [==============================] - 0s 783us/step - loss: 11328.8213\nEpoch 16/200\n226/226 [==============================] - 0s 743us/step - loss: 11099.4404\nEpoch 17/200\n226/226 [==============================] - 0s 686us/step - loss: 10872.7129\nEpoch 18/200\n226/226 [==============================] - 0s 810us/step - loss: 10648.5977\nEpoch 19/200\n226/226 [==============================] - 0s 850us/step - loss: 10427.0361\nEpoch 20/200\n226/226 [==============================] - 0s 845us/step - loss: 10207.9736\nEpoch 21/200\n226/226 [==============================] - 0s 867us/step - loss: 9991.4609\nEpoch 22/200\n226/226 [==============================] - 0s 792us/step - loss: 9777.4932\nEpoch 23/200\n226/226 [==============================] - 0s 929us/step - loss: 9566.0439\nEpoch 24/200\n226/226 [==============================] - 0s 699us/step - loss: 9357.0098\nEpoch 25/200\n226/226 [==============================] - 0s 659us/step - loss: 9150.4287\nEpoch 26/200\n226/226 [==============================] - 0s 730us/step - loss: 8946.2910\nEpoch 27/200\n226/226 [==============================] - 0s 655us/step - loss: 8744.6289\nEpoch 28/200\n226/226 [==============================] - 0s 819us/step - loss: 8545.4473\nEpoch 29/200\n226/226 [==============================] - 0s 823us/step - loss: 8348.6934\nEpoch 30/200\n226/226 [==============================] - 0s 925us/step - loss: 8154.3604\nEpoch 31/200\n226/226 [==============================] - 0s 832us/step - loss: 7962.5352\nEpoch 32/200\n226/226 [==============================] - 0s 796us/step - loss: 7773.1143\nEpoch 33/200\n226/226 [==============================] - 0s 836us/step - loss: 7586.0522\nEpoch 34/200\n226/226 [==============================] - 0s 801us/step - loss: 7401.4399\nEpoch 35/200\n226/226 [==============================] - 0s 712us/step - loss: 7219.2051\nEpoch 36/200\n226/226 [==============================] - 0s 673us/step - loss: 7039.4248\nEpoch 37/200\n226/226 [==============================] - 0s 708us/step - loss: 6862.0244\nEpoch 38/200\n226/226 [==============================] - 0s 863us/step - loss: 6687.0889\nEpoch 39/200\n226/226 [==============================] - 0s 867us/step - loss: 6514.5425\nEpoch 40/200\n226/226 [==============================] - 0s 850us/step - loss: 6344.4077\nEpoch 41/200\n226/226 [==============================] - 0s 841us/step - loss: 6176.6328\nEpoch 42/200\n226/226 [==============================] - 0s 867us/step - loss: 6011.2402\nEpoch 43/200\n226/226 [==============================] - 0s 850us/step - loss: 5848.2769\nEpoch 44/200\n226/226 [==============================] - 0s 823us/step - loss: 5687.6094\nEpoch 45/200\n226/226 [==============================] - 0s 951us/step - loss: 5529.3276\nEpoch 46/200\n226/226 [==============================] - 0s 814us/step - loss: 5373.4722\nEpoch 47/200\n226/226 [==============================] - 0s 863us/step - loss: 5220.0337\nEpoch 48/200\n226/226 [==============================] - 0s 810us/step - loss: 5068.9116\nEpoch 49/200\n226/226 [==============================] - 0s 823us/step - loss: 4920.2656\nEpoch 50/200\n226/226 [==============================] - 0s 712us/step - loss: 4774.0298\nEpoch 51/200\n226/226 [==============================] - 0s 695us/step - loss: 4630.0576\nEpoch 52/200\n226/226 [==============================] - 0s 659us/step - loss: 4488.4604\nEpoch 53/200\n226/226 [==============================] - 0s 677us/step - loss: 4349.2705\nEpoch 54/200\n226/226 [==============================] - 0s 845us/step - loss: 4212.4395\nEpoch 55/200\n226/226 [==============================] - 0s 827us/step - loss: 4077.9712\nEpoch 56/200\n226/226 [==============================] - 0s 885us/step - loss: 3945.8523\nEpoch 57/200\n226/226 [==============================] - 0s 845us/step - loss: 3816.1150\nEpoch 58/200\n226/226 [==============================] - 0s 761us/step - loss: 3688.6904\nEpoch 59/200\n226/226 [==============================] - 0s 867us/step - loss: 3563.6304\nEpoch 60/200\n226/226 [==============================] - 0s 814us/step - loss: 3440.8452\nEpoch 61/200\n226/226 [==============================] - 0s 827us/step - loss: 3320.4836\nEpoch 62/200\n226/226 [==============================] - 0s 801us/step - loss: 3202.4216\nEpoch 63/200\n226/226 [==============================] - 0s 774us/step - loss: 3086.6943\nEpoch 64/200\n226/226 [==============================] - 0s 783us/step - loss: 2973.3289\nEpoch 65/200\n226/226 [==============================] - 0s 779us/step - loss: 2862.3035\nEpoch 66/200\n226/226 [==============================] - 0s 805us/step - loss: 2753.6248\nEpoch 67/200\n226/226 [==============================] - 0s 841us/step - loss: 2647.1790\nEpoch 68/200\n226/226 [==============================] - 0s 889us/step - loss: 2543.0469\nEpoch 69/200\n226/226 [==============================] - 0s 779us/step - loss: 2441.2305\nEpoch 70/200\n226/226 [==============================] - 0s 752us/step - loss: 2341.7227\nEpoch 71/200\n226/226 [==============================] - 0s 779us/step - loss: 2244.5210\nEpoch 72/200\n226/226 [==============================] - 0s 827us/step - loss: 2149.5457\nEpoch 73/200\n226/226 [==============================] - 0s 876us/step - loss: 2056.9070\nEpoch 74/200\n226/226 [==============================] - 0s 792us/step - loss: 1966.5635\nEpoch 75/200\n226/226 [==============================] - 0s 779us/step - loss: 1878.5280\nEpoch 76/200\n226/226 [==============================] - 0s 783us/step - loss: 1792.7576\nEpoch 77/200\n226/226 [==============================] - 0s 765us/step - loss: 1709.1864\nEpoch 78/200\n226/226 [==============================] - 0s 845us/step - loss: 1627.9447\nEpoch 79/200\n226/226 [==============================] - 0s 823us/step - loss: 1548.9075\nEpoch 80/200\n226/226 [==============================] - 0s 841us/step - loss: 1472.0371\nEpoch 81/200\n226/226 [==============================] - 0s 827us/step - loss: 1397.4275\nEpoch 82/200\n226/226 [==============================] - 0s 863us/step - loss: 1325.0525\nEpoch 83/200\n226/226 [==============================] - 0s 796us/step - loss: 1254.9486\nEpoch 84/200\n226/226 [==============================] - 0s 845us/step - loss: 1186.9980\nEpoch 85/200\n226/226 [==============================] - 0s 841us/step - loss: 1121.2612\nEpoch 86/200\n226/226 [==============================] - 0s 823us/step - loss: 1057.7482\nEpoch 87/200\n226/226 [==============================] - 0s 903us/step - loss: 996.3651\nEpoch 88/200\n226/226 [==============================] - 0s 832us/step - loss: 937.1497\nEpoch 89/200\n226/226 [==============================] - 0s 850us/step - loss: 880.0379\nEpoch 90/200\n226/226 [==============================] - 0s 712us/step - loss: 825.0871\nEpoch 91/200\n226/226 [==============================] - 0s 703us/step - loss: 772.3038\nEpoch 92/200\n226/226 [==============================] - 0s 704us/step - loss: 721.6138\nEpoch 93/200\n226/226 [==============================] - 0s 730us/step - loss: 672.9846\nEpoch 94/200\n226/226 [==============================] - 0s 664us/step - loss: 626.4668\nEpoch 95/200\n226/226 [==============================] - 0s 783us/step - loss: 582.0614\nEpoch 96/200\n226/226 [==============================] - 0s 845us/step - loss: 539.6835\nEpoch 97/200\n226/226 [==============================] - 0s 854us/step - loss: 499.3688\nEpoch 98/200\n226/226 [==============================] - 0s 863us/step - loss: 461.0432\nEpoch 99/200\n226/226 [==============================] - 0s 814us/step - loss: 424.7217\nEpoch 100/200\n226/226 [==============================] - 0s 850us/step - loss: 390.3408\nEpoch 101/200\n226/226 [==============================] - 0s 898us/step - loss: 357.9070\nEpoch 102/200\n226/226 [==============================] - 0s 1ms/step - loss: 327.3973\nEpoch 103/200\n226/226 [==============================] - 0s 1ms/step - loss: 298.8260\nEpoch 104/200\n226/226 [==============================] - 0s 1ms/step - loss: 272.0482\nEpoch 105/200\n226/226 [==============================] - 0s 1ms/step - loss: 247.0925\nEpoch 106/200\n226/226 [==============================] - 0s 1ms/step - loss: 223.9323\nEpoch 107/200\n226/226 [==============================] - 0s 1ms/step - loss: 202.5084\nEpoch 108/200\n226/226 [==============================] - 0s 1ms/step - loss: 182.7590\nEpoch 109/200\n226/226 [==============================] - 0s 987us/step - loss: 164.6990\nEpoch 110/200\n226/226 [==============================] - 0s 956us/step - loss: 148.2629\nEpoch 111/200\n226/226 [==============================] - 0s 872us/step - loss: 133.3754\nEpoch 112/200\n226/226 [==============================] - 0s 876us/step - loss: 120.0264\nEpoch 113/200\n226/226 [==============================] - 0s 1ms/step - loss: 108.1093\nEpoch 114/200\n226/226 [==============================] - 0s 1ms/step - loss: 97.5744\nEpoch 115/200\n226/226 [==============================] - 0s 1ms/step - loss: 88.3765\nEpoch 116/200\n226/226 [==============================] - 0s 1ms/step - loss: 80.4159\nEpoch 117/200\n226/226 [==============================] - 0s 1ms/step - loss: 73.6200\nEpoch 118/200\n226/226 [==============================] - 0s 1ms/step - loss: 67.8981\nEpoch 119/200\n226/226 [==============================] - 0s 1ms/step - loss: 63.1599\nEpoch 120/200\n226/226 [==============================] - 0s 1ms/step - loss: 59.2853\nEpoch 121/200\n226/226 [==============================] - 0s 1ms/step - loss: 56.1930\nEpoch 122/200\n226/226 [==============================] - 0s 1ms/step - loss: 53.7810\nEpoch 123/200\n226/226 [==============================] - 0s 925us/step - loss: 51.9262\nEpoch 124/200\n226/226 [==============================] - 0s 951us/step - loss: 50.5499\nEpoch 125/200\n226/226 [==============================] - 0s 1ms/step - loss: 49.5482\nEpoch 126/200\n226/226 [==============================] - 0s 1ms/step - loss: 48.8309\nEpoch 127/200\n226/226 [==============================] - 0s 1ms/step - loss: 45.2228\nEpoch 128/200\n226/226 [==============================] - 0s 1ms/step - loss: 28.3094\nEpoch 129/200\n226/226 [==============================] - 0s 1ms/step - loss: 24.0681\nEpoch 130/200\n226/226 [==============================] - 0s 1ms/step - loss: 21.3790\nEpoch 131/200\n226/226 [==============================] - 0s 1ms/step - loss: 19.5693\nEpoch 132/200\n226/226 [==============================] - 0s 1ms/step - loss: 17.9548\nEpoch 133/200\n226/226 [==============================] - 0s 1ms/step - loss: 16.7399\nEpoch 134/200\n226/226 [==============================] - 0s 1ms/step - loss: 15.9157\nEpoch 135/200\n226/226 [==============================] - 0s 1ms/step - loss: 15.3621\nEpoch 136/200\n226/226 [==============================] - 0s 996us/step - loss: 15.0270\nEpoch 137/200\n226/226 [==============================] - 0s 898us/step - loss: 14.5720\nEpoch 138/200\n226/226 [==============================] - 0s 942us/step - loss: 14.3090\nEpoch 139/200\n226/226 [==============================] - 0s 1ms/step - loss: 14.0084\nEpoch 140/200\n226/226 [==============================] - 0s 934us/step - loss: 14.0507\nEpoch 141/200\n226/226 [==============================] - 0s 947us/step - loss: 13.9026\nEpoch 142/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.7934\nEpoch 143/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.6660\nEpoch 144/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.7042\nEpoch 145/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.6165\nEpoch 146/200\n226/226 [==============================] - 0s 987us/step - loss: 13.4487\nEpoch 147/200\n226/226 [==============================] - 0s 969us/step - loss: 13.3967\nEpoch 148/200\n226/226 [==============================] - 0s 956us/step - loss: 13.4148\nEpoch 149/200\n226/226 [==============================] - 0s 982us/step - loss: 13.5524\nEpoch 150/200\n226/226 [==============================] - 0s 929us/step - loss: 13.2661\nEpoch 151/200\n226/226 [==============================] - 0s 885us/step - loss: 13.0910\nEpoch 152/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.3863\nEpoch 153/200\n226/226 [==============================] - 0s 1ms/step - loss: 13.4083\nEpoch 154/200\n226/226 [==============================] - 0s 1ms/step - loss: 12.8760\nEpoch 155/200\n226/226 [==============================] - 0s 1ms/step - loss: 12.5183\nEpoch 156/200\n226/226 [==============================] - 0s 1ms/step - loss: 12.4481\nEpoch 157/200\n226/226 [==============================] - 0s 973us/step - loss: 11.2258\nEpoch 158/200\n226/226 [==============================] - 0s 916us/step - loss: 10.0393\nEpoch 159/200\n226/226 [==============================] - 0s 1ms/step - loss: 7.8765\nEpoch 160/200\n226/226 [==============================] - 0s 1ms/step - loss: 7.5240\nEpoch 161/200\n226/226 [==============================] - 0s 1ms/step - loss: 6.7364\nEpoch 162/200\n226/226 [==============================] - 0s 1ms/step - loss: 6.4959\nEpoch 163/200\n226/226 [==============================] - 0s 1ms/step - loss: 5.8313\nEpoch 164/200\n226/226 [==============================] - 0s 1ms/step - loss: 5.9889\nEpoch 165/200\n226/226 [==============================] - 0s 973us/step - loss: 5.3868\nEpoch 166/200\n226/226 [==============================] - 0s 960us/step - loss: 5.2553\nEpoch 167/200\n226/226 [==============================] - 0s 920us/step - loss: 5.0553\nEpoch 168/200\n226/226 [==============================] - 0s 867us/step - loss: 5.3571\nEpoch 169/200\n226/226 [==============================] - 0s 912us/step - loss: 4.8444\nEpoch 170/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.8047\nEpoch 171/200\n226/226 [==============================] - 0s 1ms/step - loss: 5.1783\nEpoch 172/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.7096\nEpoch 173/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.8036\nEpoch 174/200\n226/226 [==============================] - 0s 978us/step - loss: 4.6781\nEpoch 175/200\n226/226 [==============================] - 0s 907us/step - loss: 4.5465\nEpoch 176/200\n226/226 [==============================] - 0s 920us/step - loss: 4.3353\nEpoch 177/200\n226/226 [==============================] - 0s 991us/step - loss: 4.4446\nEpoch 178/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.5276\nEpoch 179/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.2988\nEpoch 180/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.2748\nEpoch 181/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.5525\nEpoch 182/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.3954\nEpoch 183/200\n226/226 [==============================] - 0s 965us/step - loss: 4.0594\nEpoch 184/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.2011\nEpoch 185/200\n226/226 [==============================] - 0s 960us/step - loss: 4.1050\nEpoch 186/200\n226/226 [==============================] - 0s 969us/step - loss: 3.9386\nEpoch 187/200\n226/226 [==============================] - 0s 960us/step - loss: 4.3953\nEpoch 188/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.3143\nEpoch 189/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.9669\nEpoch 190/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.9407\nEpoch 191/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.8299\nEpoch 192/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.0983\nEpoch 193/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.7110\nEpoch 194/200\n220/226 [============================>.] - ETA: 0s - loss: 3.866226/226 [==============================] - 0s 1ms/step - loss: 3.8568\nEpoch 195/200\n226/226 [==============================] - 0s 1ms/step - loss: 4.0067\nEpoch 196/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.6729\nEpoch 197/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.9407\nEpoch 198/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.2247\nEpoch 199/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.6643\nEpoch 200/200\n226/226 [==============================] - 0s 1ms/step - loss: 3.5957\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1f47026c160>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size=5, epochs=200, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[133.13 130.79]\n [120.1  119.54]\n [111.68 110.32]\n [117.23 117.4 ]\n [126.35 127.62]\n [120.75 121.66]\n [120.11 118.69]\n [131.08 130.03]\n [114.1  114.73]\n [125.79 124.21]\n [127.03 125.84]\n [132.12 131.52]\n [131.74 130.7 ]\n [117.87 117.81]\n [126.98 126.66]\n [114.72 113.14]\n [127.69 126.76]\n [132.48 133.38]\n [119.28 118.08]\n [117.22 116.15]\n [121.53 123.46]\n [130.95 130.09]\n [130.71 129.93]\n [122.81 120.66]\n [132.9  134.06]\n [121.62 122.09]\n [115.93 117.09]\n [132.63 138.76]\n [130.8  130.83]\n [130.24 128.24]\n [126.47 128.95]\n [123.88 122.53]\n [103.09 103.38]\n [131.37 126.41]\n [131.47 131.8 ]\n [131.85 130.96]\n [118.63 119.25]\n [112.04 109.64]\n [127.46 127.78]\n [125.77 129.01]\n [132.85 132.54]\n [125.25 125.48]\n [129.88 138.27]\n [122.17 123.13]\n [111.04 111.03]\n [134.1  135.96]\n [129.17 127.12]\n [130.06 129.67]\n [125.49 125.65]\n [127.23 129.24]\n [123.5  123.21]\n [125.77 127.  ]\n [118.35 119.91]\n [126.15 126.56]\n [121.33 121.53]\n [122.71 122.23]\n [114.39 113.3 ]\n [128.06 128.34]\n [122.59 121.73]\n [119.07 118.9 ]\n [124.74 122.43]\n [132.39 133.24]\n [126.69 127.64]\n [133.96 136.17]\n [125.07 124.36]\n [128.7  127.59]\n [126.68 128.35]\n [131.42 133.76]\n [131.95 132.13]\n [114.39 113.8 ]\n [125.16 125.72]\n [127.17 126.09]\n [124.77 121.01]\n [129.9  130.05]\n [126.9  126.65]\n [124.87 123.45]\n [121.54 122.09]\n [124.86 126.51]\n [133.07 133.66]\n [130.6  130.18]\n [128.   129.12]\n [127.55 128.41]\n [117.63 118.11]\n [125.33 122.8 ]\n [127.73 127.31]\n [118.61 118.11]\n [128.23 128.81]\n [123.22 121.77]\n [133.42 134.53]\n [127.41 127.38]\n [131.46 130.99]\n [129.58 127.12]\n [121.73 119.11]\n [111.37 110.65]\n [125.21 126.42]\n [107.46 107.28]\n [110.05 108.19]\n [134.04 136.1 ]\n [120.71 120.51]\n [122.16 122.78]\n [125.32 125.16]\n [133.78 135.94]\n [127.78 129.01]\n [131.08 131.86]\n [133.75 133.28]\n [128.15 129.58]\n [132.75 133.05]\n [130.2  130.79]\n [131.48 131.71]\n [133.65 136.68]\n [126.71 123.23]\n [124.72 125.04]\n [126.25 127.83]\n [126.05 127.46]\n [126.63 129.09]\n [121.72 120.98]\n [130.07 130.72]\n [119.1  120.7 ]\n [127.5  128.63]\n [125.71 122.2 ]\n [124.78 123.3 ]\n [123.21 119.7 ]\n [125.23 127.31]\n [127.22 127.14]\n [126.14 124.46]\n [119.46 116.02]\n [130.94 131.72]\n [127.17 129.69]\n [127.01 126.84]\n [120.86 120.65]\n [128.7  131.36]\n [127.15 123.22]\n [123.24 125.63]\n [119.04 115.44]\n [130.22 128.33]\n [123.63 125.97]\n [119.01 120.58]\n [131.93 132.66]\n [123.75 123.21]\n [113.08 112.16]\n [113.63 114.08]\n [114.14 114.67]\n [130.73 127.81]\n [119.51 123.26]\n [116.79 116.66]\n [125.45 122.97]\n [114.94 116.47]\n [129.04 129.27]\n [120.74 121.12]\n [129.69 130.43]\n [125.85 125.57]\n [131.73 131.6 ]\n [115.63 119.15]\n [124.07 123.24]\n [120.26 126.51]\n [122.76 122.82]\n [131.57 133.5 ]\n [127.5  126.93]\n [120.75 119.88]\n [133.25 133.96]\n [115.08 113.73]\n [126.02 125.05]\n [124.39 125.23]\n [131.22 130.24]\n [125.03 124.51]\n [128.01 128.26]\n [124.76 124.88]\n [118.31 118.62]\n [133.9  138.54]\n [113.14 112.93]\n [114.63 113.08]\n [129.88 128.17]\n [126.96 125.81]\n [127.24 124.99]\n [127.23 126.84]\n [115.58 116.86]\n [124.12 125.72]\n [125.14 123.12]\n [126.27 125.31]\n [121.96 122.17]\n [129.86 131.46]\n [120.96 121.59]\n [133.69 134.15]\n [118.47 119.19]\n [126.95 125.95]\n [132.18 129.95]\n [128.31 127.58]\n [129.58 129.58]\n [121.59 120.26]\n [125.32 126.16]\n [126.61 124.84]\n [119.07 119.14]\n [125.53 126.81]\n [126.78 125.96]\n [119.53 118.62]\n [134.17 134.93]\n [127.6  130.72]\n [115.11 113.08]\n [123.71 121.85]\n [124.38 126.34]\n [113.47 114.45]\n [130.37 130.59]\n [126.6  126.99]\n [124.4  126.41]\n [108.88 106.11]\n [129.99 130.22]\n [130.23 131.07]\n [119.65 118.13]\n [119.05 118.55]\n [128.83 130.99]\n [133.63 130.5 ]\n [131.85 131.78]\n [125.56 127.4 ]\n [127.49 125.2 ]\n [128.5  130.03]\n [127.79 130.21]\n [133.7  138.42]\n [131.12 128.82]\n [132.13 133.61]\n [117.15 117.65]\n [129.25 130.4 ]\n [131.52 132.4 ]\n [131.38 131.75]\n [117.15 116.02]\n [124.63 123.74]\n [113.11 108.65]\n [130.2  129.88]\n [126.44 126.47]\n [127.95 128.58]\n [118.42 115.81]\n [128.96 128.18]\n [125.91 126.15]\n [124.1  126.67]\n [131.43 132.3 ]\n [116.   117.72]\n [124.63 124.09]\n [128.6  128.44]\n [124.81 127.69]\n [117.36 118.77]\n [126.63 126.27]\n [120.38 121.06]\n [127.68 128.48]\n [128.25 126.86]\n [114.31 114.78]\n [107.72 107.15]\n [118.28 120.24]\n [127.06 127.36]\n [128.45 124.16]\n [124.88 124.36]\n [128.64 128.56]\n [109.04 108.69]\n [110.26 109.89]\n [131.55 136.41]\n [132.07 133.55]\n [125.05 125.03]\n [124.48 123.7 ]\n [120.66 120.25]\n [126.08 128.71]\n [117.89 117.14]\n [105.5  104.5 ]\n [123.92 125.35]\n [122.99 119.1 ]\n [120.72 121.24]\n [132.3  128.92]\n [124.84 125.35]\n [133.41 134.32]\n [130.45 130.56]\n [131.22 132.76]\n [116.82 120.14]\n [128.48 130.75]\n [130.84 128.68]\n [126.69 125.11]\n [133.52 134.31]\n [125.37 124.84]\n [130.96 127.56]\n [128.99 125.68]\n [123.93 122.23]\n [128.16 128.29]\n [116.24 115.14]\n [120.14 120.23]\n [115.63 116.91]\n [130.67 133.42]\n [132.53 134.51]\n [121.01 119.97]\n [114.49 117.25]\n [128.76 129.99]\n [124.76 125.27]\n [104.88 104.2 ]\n [123.93 125.58]\n [121.1  119.29]\n [118.42 120.54]\n [130.38 129.28]\n [121.92 121.82]\n [122.2  121.93]\n [109.97 109.62]\n [134.08 138.61]\n [126.16 127.61]\n [128.76 130.44]\n [130.26 131.01]\n [129.16 125.58]\n [114.45 112.59]\n [128.97 127.21]\n [132.76 136.28]\n [118.2  117.5 ]\n [122.78 122.34]\n [113.87 114.04]\n [133.45 135.08]\n [127.45 127.23]\n [123.91 123.69]\n [120.75 118.  ]\n [134.04 135.35]\n [126.42 126.53]\n [132.4  135.37]\n [112.05 111.96]\n [128.69 125.82]\n [116.32 119.62]\n [131.88 132.04]\n [117.77 118.36]\n [125.42 124.75]\n [113.57 112.51]\n [122.41 122.38]\n [120.62 120.5 ]\n [124.25 121.31]\n [108.69 109.25]\n [119.32 119.5 ]\n [116.   118.21]\n [126.36 124.36]\n [116.62 115.91]\n [133.35 139.44]\n [123.99 124.49]\n [133.08 129.68]\n [132.01 134.53]\n [115.19 114.31]\n [130.89 129.45]\n [118.02 116.41]\n [119.46 118.13]\n [119.28 118.71]\n [132.95 131.84]\n [110.59 110.91]\n [130.16 129.57]\n [125.84 124.27]\n [128.07 129.03]\n [123.11 124.85]\n [116.33 115.68]\n [115.43 117.62]\n [126.18 127.13]\n [119.86 119.38]\n [122.14 119.07]\n [121.4  118.94]\n [112.11 113.33]\n [128.83 127.7 ]\n [131.98 131.46]\n [121.81 121.48]\n [128.19 129.8 ]\n [124.83 127.04]\n [132.08 134.  ]\n [129.85 128.77]\n [125.09 124.45]\n [123.37 124.84]\n [116.15 114.9 ]\n [118.2  118.76]\n [129.56 128.35]\n [131.24 130.2 ]\n [119.19 118.14]\n [131.25 133.1 ]\n [126.26 125.73]\n [117.65 116.24]\n [123.39 124.17]\n [114.94 115.86]\n [129.67 129.97]\n [122.73 121.4 ]\n [119.1  120.77]\n [118.87 118.12]\n [132.46 132.51]\n [132.04 132.3 ]\n [123.49 127.64]]\n"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9322909802648519"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3.2117198918874075"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.037428344726564"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}