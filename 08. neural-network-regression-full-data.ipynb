{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table(\"data/airfoil_self_noise.dat\", \n",
    "                        header=None, \n",
    "                        names=['frequency', 'angle_of_attack', 'chord_length', 'free_stream_velocity', \n",
    "                               'suction_side_displacement_thickness', 'scaled_sound_pressure_level'])\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.00e+02, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.00e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       [1.25e+03, 0.00e+00, 3.05e-01, 7.13e+01, 2.66e-03],\n       ...,\n       [4.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [5.00e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02],\n       [6.30e+03, 1.56e+01, 1.02e-01, 3.96e+01, 5.28e-02]])"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([126.2 , 125.2 , 125.95, ..., 106.6 , 106.22, 104.2 ])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "regressor = tf.keras.models.Sequential()\n",
    "regressor.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "regressor.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "regressor.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "regressor.add(tf.keras.layers.Dense(units=1))\n",
    "regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n226/226 [==============================] - 1s 4ms/step - loss: 12796.8679\nEpoch 2/50\n226/226 [==============================] - 0s 1ms/step - loss: 602.3802\nEpoch 3/50\n226/226 [==============================] - 0s 1ms/step - loss: 48.4533\nEpoch 4/50\n226/226 [==============================] - 0s 1ms/step - loss: 47.8796\nEpoch 5/50\n226/226 [==============================] - 0s 872us/step - loss: 36.4394\nEpoch 6/50\n226/226 [==============================] - 0s 704us/step - loss: 23.2498\nEpoch 7/50\n226/226 [==============================] - 0s 742us/step - loss: 19.4097\nEpoch 8/50\n226/226 [==============================] - 0s 729us/step - loss: 17.6352\nEpoch 9/50\n226/226 [==============================] - 0s 822us/step - loss: 17.8475\nEpoch 10/50\n226/226 [==============================] - 0s 723us/step - loss: 16.3315\nEpoch 11/50\n226/226 [==============================] - 0s 711us/step - loss: 15.6231\nEpoch 12/50\n226/226 [==============================] - 0s 717us/step - loss: 16.3657\nEpoch 13/50\n226/226 [==============================] - 0s 713us/step - loss: 15.3777\nEpoch 14/50\n226/226 [==============================] - 0s 856us/step - loss: 15.2484\nEpoch 15/50\n226/226 [==============================] - 0s 651us/step - loss: 14.4957\nEpoch 16/50\n226/226 [==============================] - 0s 715us/step - loss: 15.9977\nEpoch 17/50\n226/226 [==============================] - 0s 653us/step - loss: 14.0905\nEpoch 18/50\n226/226 [==============================] - 0s 710us/step - loss: 13.2720\nEpoch 19/50\n226/226 [==============================] - 0s 701us/step - loss: 14.1186\nEpoch 20/50\n226/226 [==============================] - 0s 734us/step - loss: 12.8646\nEpoch 21/50\n226/226 [==============================] - 0s 696us/step - loss: 13.5940\nEpoch 22/50\n226/226 [==============================] - 0s 744us/step - loss: 12.6333\nEpoch 23/50\n226/226 [==============================] - 0s 723us/step - loss: 12.1540\nEpoch 24/50\n226/226 [==============================] - 0s 709us/step - loss: 12.8712\nEpoch 25/50\n226/226 [==============================] - 0s 716us/step - loss: 11.9688\nEpoch 26/50\n226/226 [==============================] - 0s 728us/step - loss: 11.1974\nEpoch 27/50\n226/226 [==============================] - 0s 725us/step - loss: 10.2363\nEpoch 28/50\n226/226 [==============================] - 0s 784us/step - loss: 11.1323\nEpoch 29/50\n226/226 [==============================] - 0s 734us/step - loss: 8.9886\nEpoch 30/50\n226/226 [==============================] - 0s 720us/step - loss: 8.5148\nEpoch 31/50\n226/226 [==============================] - 0s 729us/step - loss: 10.0350\nEpoch 32/50\n226/226 [==============================] - 0s 707us/step - loss: 9.2527\nEpoch 33/50\n226/226 [==============================] - 0s 709us/step - loss: 8.8453\nEpoch 34/50\n226/226 [==============================] - 0s 717us/step - loss: 9.4199\nEpoch 35/50\n226/226 [==============================] - 0s 721us/step - loss: 7.7494\nEpoch 36/50\n226/226 [==============================] - 0s 732us/step - loss: 7.4298\nEpoch 37/50\n226/226 [==============================] - 0s 708us/step - loss: 7.9576\nEpoch 38/50\n226/226 [==============================] - 0s 716us/step - loss: 7.3075\nEpoch 39/50\n226/226 [==============================] - 0s 735us/step - loss: 8.1909\nEpoch 40/50\n226/226 [==============================] - 0s 717us/step - loss: 7.4631\nEpoch 41/50\n226/226 [==============================] - 0s 706us/step - loss: 7.0062\nEpoch 42/50\n226/226 [==============================] - 0s 700us/step - loss: 7.1574\nEpoch 43/50\n226/226 [==============================] - 0s 734us/step - loss: 8.0054\nEpoch 44/50\n226/226 [==============================] - 0s 725us/step - loss: 7.7622\nEpoch 45/50\n226/226 [==============================] - 0s 732us/step - loss: 7.1846\nEpoch 46/50\n226/226 [==============================] - 0s 792us/step - loss: 7.0422\nEpoch 47/50\n226/226 [==============================] - 0s 709us/step - loss: 7.2599\nEpoch 48/50\n226/226 [==============================] - 0s 749us/step - loss: 6.9635\nEpoch 49/50\n226/226 [==============================] - 0s 711us/step - loss: 8.2308\nEpoch 50/50\n226/226 [==============================] - 0s 720us/step - loss: 6.7277\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1baf3395370>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size=5, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[133.05 130.79]\n [121.03 119.54]\n [112.22 110.32]\n [119.59 117.4 ]\n [124.63 127.62]\n [121.59 121.66]\n [118.43 118.69]\n [130.99 130.03]\n [111.93 114.73]\n [124.95 124.21]\n [126.89 125.84]\n [131.08 131.52]\n [131.34 130.7 ]\n [117.41 117.81]\n [127.03 126.66]\n [112.1  113.14]\n [127.03 126.76]\n [131.14 133.38]\n [118.72 118.08]\n [118.92 116.15]\n [119.75 123.46]\n [131.52 130.09]\n [130.86 129.93]\n [122.98 120.66]\n [130.96 134.06]\n [121.32 122.09]\n [113.86 117.09]\n [129.69 138.76]\n [129.85 130.83]\n [129.55 128.24]\n [127.85 128.95]\n [123.19 122.53]\n [108.44 103.38]\n [127.16 126.41]\n [129.74 131.8 ]\n [130.57 130.96]\n [116.79 119.25]\n [108.32 109.64]\n [126.84 127.78]\n [122.7  129.01]\n [132.95 132.54]\n [124.27 125.48]\n [125.58 138.27]\n [116.72 123.13]\n [109.68 111.03]\n [134.35 135.96]\n [129.87 127.12]\n [129.79 129.67]\n [126.75 125.65]\n [127.38 129.24]\n [124.55 123.21]\n [126.5  127.  ]\n [118.77 119.91]\n [128.88 126.56]\n [119.45 121.53]\n [121.22 122.23]\n [112.82 113.3 ]\n [129.52 128.34]\n [121.42 121.73]\n [123.68 118.9 ]\n [127.48 122.43]\n [132.17 133.24]\n [127.15 127.64]\n [133.75 136.17]\n [124.38 124.36]\n [125.37 127.59]\n [126.17 128.35]\n [129.72 133.76]\n [131.31 132.13]\n [118.56 113.8 ]\n [127.75 125.72]\n [128.86 126.09]\n [125.45 121.01]\n [130.84 130.05]\n [126.04 126.65]\n [122.81 123.45]\n [126.1  122.09]\n [122.52 126.51]\n [133.26 133.66]\n [130.36 130.18]\n [128.9  129.12]\n [128.58 128.41]\n [123.65 118.11]\n [124.75 122.8 ]\n [126.86 127.31]\n [116.23 118.11]\n [128.51 128.81]\n [122.36 121.77]\n [132.23 134.53]\n [129.53 127.38]\n [128.85 130.99]\n [129.52 127.12]\n [125.27 119.11]\n [109.78 110.65]\n [126.01 126.42]\n [109.65 107.28]\n [111.98 108.19]\n [134.85 136.1 ]\n [120.99 120.51]\n [123.81 122.78]\n [123.84 125.16]\n [134.77 135.94]\n [124.85 129.01]\n [129.26 131.86]\n [135.38 133.28]\n [130.79 129.58]\n [131.69 133.05]\n [128.69 130.79]\n [130.46 131.71]\n [132.65 136.68]\n [124.1  123.23]\n [126.48 125.04]\n [124.63 127.83]\n [126.5  127.46]\n [126.56 129.09]\n [120.42 120.98]\n [129.93 130.72]\n [119.77 120.7 ]\n [126.88 128.63]\n [125.28 122.2 ]\n [123.27 123.3 ]\n [123.38 119.7 ]\n [125.56 127.31]\n [128.04 127.14]\n [125.72 124.46]\n [113.77 116.02]\n [130.14 131.72]\n [126.17 129.69]\n [126.15 126.84]\n [119.4  120.65]\n [129.33 131.36]\n [126.62 123.22]\n [121.72 125.63]\n [120.42 115.44]\n [127.21 128.33]\n [126.79 125.97]\n [125.   120.58]\n [130.32 132.66]\n [121.66 123.21]\n [111.25 112.16]\n [111.8  114.08]\n [112.19 114.67]\n [131.24 127.81]\n [123.32 123.26]\n [113.73 116.66]\n [125.47 122.97]\n [113.66 116.47]\n [127.34 129.27]\n [120.38 121.12]\n [128.09 130.43]\n [124.77 125.57]\n [131.73 131.6 ]\n [118.51 119.15]\n [122.26 123.24]\n [121.72 126.51]\n [122.01 122.82]\n [130.12 133.5 ]\n [129.88 126.93]\n [120.96 119.88]\n [134.76 133.96]\n [113.19 113.73]\n [125.01 125.05]\n [123.96 125.23]\n [128.69 130.24]\n [122.79 124.51]\n [126.91 128.26]\n [124.44 124.88]\n [117.88 118.62]\n [134.18 138.54]\n [113.6  112.93]\n [111.78 113.08]\n [128.15 128.17]\n [126.6  125.81]\n [127.18 124.99]\n [127.65 126.84]\n [113.53 116.86]\n [125.37 125.72]\n [126.52 123.12]\n [126.47 125.31]\n [119.91 122.17]\n [127.89 131.46]\n [121.82 121.59]\n [133.61 134.15]\n [119.94 119.19]\n [129.7  125.95]\n [130.07 129.95]\n [128.05 127.58]\n [127.62 129.58]\n [120.61 120.26]\n [124.13 126.16]\n [124.48 124.84]\n [119.65 119.14]\n [127.72 126.81]\n [127.16 125.96]\n [118.21 118.62]\n [135.06 134.93]\n [125.61 130.72]\n [113.46 113.08]\n [125.26 121.85]\n [125.33 126.34]\n [114.14 114.45]\n [129.22 130.59]\n [127.43 126.99]\n [126.23 126.41]\n [108.72 106.11]\n [126.25 130.22]\n [128.51 131.07]\n [119.59 118.13]\n [117.36 118.55]\n [127.15 130.99]\n [135.38 130.5 ]\n [130.54 131.78]\n [127.33 127.4 ]\n [129.78 125.2 ]\n [127.43 130.03]\n [125.8  130.21]\n [133.15 138.42]\n [127.6  128.82]\n [131.53 133.61]\n [115.38 117.65]\n [127.91 130.4 ]\n [131.64 132.4 ]\n [130.59 131.75]\n [117.28 116.02]\n [124.05 123.74]\n [110.29 108.65]\n [128.68 129.88]\n [127.28 126.47]\n [127.85 128.58]\n [124.92 115.81]\n [128.75 128.18]\n [125.34 126.15]\n [122.74 126.67]\n [130.76 132.3 ]\n [118.23 117.72]\n [122.75 124.09]\n [129.34 128.44]\n [124.98 127.69]\n [116.42 118.77]\n [127.26 126.27]\n [120.86 121.06]\n [126.72 128.48]\n [127.51 126.86]\n [112.84 114.78]\n [109.47 107.15]\n [121.29 120.24]\n [127.62 127.36]\n [123.85 124.16]\n [123.38 124.36]\n [129.01 128.56]\n [108.89 108.69]\n [109.2  109.89]\n [130.1  136.41]\n [132.07 133.55]\n [124.45 125.03]\n [126.81 123.7 ]\n [119.03 120.25]\n [124.13 128.71]\n [118.02 117.14]\n [108.86 104.5 ]\n [123.42 125.35]\n [123.53 119.1 ]\n [124.03 121.24]\n [133.62 128.92]\n [126.37 125.35]\n [133.15 134.32]\n [129.26 130.56]\n [129.93 132.76]\n [118.86 120.14]\n [125.   130.75]\n [128.54 128.68]\n [126.36 125.11]\n [133.32 134.31]\n [124.85 124.84]\n [127.32 127.56]\n [127.75 125.68]\n [124.49 122.23]\n [128.65 128.29]\n [114.45 115.14]\n [117.59 120.23]\n [114.09 116.91]\n [130.65 133.42]\n [132.15 134.51]\n [126.1  119.97]\n [115.63 117.25]\n [129.3  129.99]\n [127.69 125.27]\n [108.52 104.2 ]\n [128.48 125.58]\n [121.93 119.29]\n [119.51 120.54]\n [129.37 129.28]\n [119.31 121.82]\n [121.89 121.93]\n [109.08 109.62]\n [134.82 138.61]\n [126.16 127.61]\n [127.28 130.44]\n [129.61 131.01]\n [127.96 125.58]\n [111.6  112.59]\n [124.06 127.21]\n [130.   136.28]\n [113.88 117.5 ]\n [124.39 122.34]\n [111.86 114.04]\n [133.02 135.08]\n [124.93 127.23]\n [124.13 123.69]\n [124.99 118.  ]\n [135.41 135.35]\n [124.14 126.53]\n [131.39 135.37]\n [110.3  111.96]\n [124.34 125.82]\n [120.54 119.62]\n [129.27 132.04]\n [116.19 118.36]\n [123.19 124.75]\n [118.24 112.51]\n [123.24 122.38]\n [118.79 120.5 ]\n [123.82 121.31]\n [110.3  109.25]\n [118.42 119.5 ]\n [114.34 118.21]\n [127.04 124.36]\n [116.42 115.91]\n [130.89 139.44]\n [126.55 124.49]\n [127.93 129.68]\n [130.59 134.53]\n [113.88 114.31]\n [120.52 129.45]\n [118.04 116.41]\n [122.51 118.13]\n [118.56 118.71]\n [134.15 131.84]\n [110.79 110.91]\n [129.39 129.57]\n [125.97 124.27]\n [127.38 129.03]\n [123.54 124.85]\n [114.37 115.68]\n [113.02 117.62]\n [123.32 127.13]\n [120.18 119.38]\n [125.44 119.07]\n [119.86 118.94]\n [112.64 113.33]\n [127.65 127.7 ]\n [132.91 131.46]\n [121.31 121.48]\n [128.54 129.8 ]\n [123.62 127.04]\n [130.69 134.  ]\n [130.37 128.77]\n [126.   124.45]\n [122.7  124.84]\n [115.48 114.9 ]\n [118.6  118.76]\n [127.82 128.35]\n [132.84 130.2 ]\n [117.87 118.14]\n [130.73 133.1 ]\n [121.84 125.73]\n [116.52 116.24]\n [126.16 124.17]\n [120.85 115.86]\n [131.69 129.97]\n [122.09 121.4 ]\n [120.6  120.77]\n [119.59 118.12]\n [131.39 132.51]\n [132.24 132.3 ]\n [123.76 127.64]]\n"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8561708997652258"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6.822411313340832"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.4440497436523287"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}